{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "of3Gq9hHvsnm",
        "outputId": "f471d75a-f0ca-43e4-f8a9-d774d4e675fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58FaU9vsOkCi"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# load data\n",
        "df = pd.read_excel('/content/drive/MyDrive/Colab Notebooks/College/Research Haikal/dataset1.xlsx', index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ldPs_2XOkCl"
      },
      "outputs": [],
      "source": [
        "# create a dictionary to translate column names\n",
        "translation_dict = {'Wavelenth': 'Wavelength', \n",
        "                    'indeks bias': 'Refractive index',\n",
        "                    'diameter hole': 'Hole diameter', \n",
        "                    'ketebalan emas': 'Gold thickness',\n",
        "                    'ketebalan TiO2': 'TiO2 thickness', \n",
        "                    'confinement Loss': 'Confinement loss'}\n",
        "\n",
        "# rename the columns using the translation dictionary\n",
        "df = df.rename(columns=translation_dict)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['TiO2 thickness']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lS7QMl2ow4hJ",
        "outputId": "a99e1b13-d2e6-473e-b959-5142ea3aa033"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      45\n",
              "1      45\n",
              "2      45\n",
              "3      45\n",
              "4      45\n",
              "       ..\n",
              "739    35\n",
              "740    35\n",
              "741    35\n",
              "742    35\n",
              "743    35\n",
              "Name: TiO2 thickness, Length: 744, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.layers import Dense\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load the data\n",
        "data = df\n",
        "\n",
        "# Preprocess the data\n",
        "X = data.iloc[:, :-1].values #data input\n",
        "y = data.iloc[:, -1].values #data output\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMeCv6clw5zJ",
        "outputId": "e1def489-7868-4592-ceb5-9fd6d43e0245"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.62,  1.36,  1.5 , 35.  , 35.  ],\n",
              "       [ 0.59,  1.35,  1.5 , 50.  , 45.  ],\n",
              "       [ 0.73,  1.36,  1.5 , 35.  , 35.  ],\n",
              "       ...,\n",
              "       [ 0.64,  1.36,  1.51, 45.  , 35.  ],\n",
              "       [ 0.56,  1.36,  1.5 , 45.  , 35.  ],\n",
              "       [ 0.57,  1.36,  1.48, 45.  , 35.  ]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[:,3]"
      ],
      "metadata": {
        "id": "CT-3HTg615fg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(f'scaled: {X_train_scaled}')\n",
        "print(f'X_train:{X_train}')\n",
        "\n",
        "for i, j in zip(X_train_scaled,X_train):\n",
        "  for k,l in zip(i,j):\n",
        "    print(k,l)"
      ],
      "metadata": {
        "id": "wGYfZ5cWxA0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_scaled[:][3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nATZqqVH1YPa",
        "outputId": "217d71ca-717c-49eb-d853-c0ee4e7c5764"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.22486172,  0.10378951, -1.58402709, -0.22894514, -0.97977962])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "plt.hist(X_train_scaled[:,3],X_train[:,3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "woc4goH00Knz",
        "outputId": "b5c0aa93-cf71-433e-9f44-33e10c601c81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f2bc3220dc0>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGdCAYAAAAxCSikAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAt40lEQVR4nO3df3BUVZ7//1eTkA4SuhEC6eRLgEAwETE6xO/Eplh/JZAgNQaJY6mZiViMWVjWEVHBUIjLgpUUWiPiroAOotTHHVYYo6gjrmQk7KwhgwGKLI4pEhMBkw4fY6UbgmmccL9/+KVrWkJI5+dJ5vmoOlX0ueecvA9N2y9v376xWZZlCQAAwGBD+rsAAACAKyGwAAAA4xFYAACA8QgsAADAeAQWAABgPAILAAAwHoEFAAAYj8ACAACMF97fBfSECxcuqL6+XiNGjJDNZuvvcgAAQCdYlqUzZ84oLi5OQ4Z0fA5lUASW+vp6xcfH93cZAACgC06ePKlx48Z1OGZQBJYRI0ZI+mHDDoejn6sBAACd4fP5FB8fH3gf78igCCwXPwZyOBwEFgAABpjOXM7BRbcAAMB4BBYAAGA8AgsAADAegQUAABiPwAIAAIxHYAEAAMYjsAAAAOMRWAAAgPEGxY3jAABA75j41AeX9NUVze3zOkI6w/Iv//IvstlsQS05OTlwvLW1VUuWLNHo0aMVFRWlnJwcNTY2drimZVlavXq1YmNjNWzYMGVkZOj48eNd2w0AAOgx7YWVjvp7U8gfCV133XVqaGgItD/96U+BY4899pjee+897dy5U6Wlpaqvr9f8+fM7XG/9+vXauHGjNm/erPLycg0fPlyZmZlqbW0NfTcAAKBHXCmU9HVoCTmwhIeHy+VyBVp0dLQkyev1auvWrfrNb36jO+64Q6mpqdq2bZs+/fRTHThwoN21LMvShg0btGrVKmVnZyslJUXbt29XfX293nnnnW5tDAAAdE1nw0hfhpaQA8vx48cVFxenSZMmKTc3VydOnJAkVVRU6Pvvv1dGRkZgbHJyssaPH6+ysrJ216qtrZXH4wma43Q6lZaWdtk5kuT3++Xz+YIaAAAYvEIKLGlpaXr99de1Z88ebdq0SbW1tfqHf/gHnTlzRh6PRxERERo5cmTQnJiYGHk8nnbXu9gfExPT6TmSVFhYKKfTGWjx8fGhbAMAAAwwIX1LaM6cOYE/p6SkKC0tTRMmTNBbb72lYcOG9Xhxl1NQUKBly5YFHvt8PkILAACDWLfuwzJy5Ehdc801qq6ulsvl0vnz59Xc3Bw0prGxUS6Xq935F/t//E2ijuZIkt1ul8PhCGoAAGDw6lZgOXv2rGpqahQbG6vU1FQNHTpUJSUlgeNVVVU6ceKE3G53u/MTEhLkcrmC5vh8PpWXl192DgAA6F2dvc9KX96PJaTA8sQTT6i0tFR1dXX69NNPdffddyssLEz333+/nE6nFi5cqGXLlumTTz5RRUWFHnroIbndbt18882BNZKTk1VcXCxJstlsWrp0qdatW6fdu3ersrJSeXl5iouL07x583p0owAAoPOuFEb6+uZxIV3DcurUKd1///1qamrSmDFjNHPmTB04cEBjxoyRJL3wwgsaMmSIcnJy5Pf7lZmZqZdffjlojaqqKnm93sDj5cuXq6WlRfn5+WpubtbMmTO1Z88eRUZG9sD2AABAV9UVzTXmTrc2y7KsPv+pPczn88npdMrr9XI9CwAAA0Qo79/88kMAAGA8AgsAADAegQUAABiPwAIAAIxHYAEAAMYjsAAAAOMRWAAAgPEILAAAwHgEFgAAYDwCCwAAMB6BBQAAGI/AAgAAjEdgAQAAxiOwAAAA4xFYAACA8QgsAADAeAQWAABgPAILAAAwHoEFAAAYj8ACAACMR2ABAADGI7AAAADjEVgAAIDxCCwAAMB4BBYAAGA8AgsAADAegQUAABiPwAIAAIxHYAEAAMYjsAAAAOMRWAAAgPG6FViKiopks9m0dOlSSVJdXZ1sNlu7befOnZddZ8GCBZeMz8rK6k5pAABgEAnv6sSDBw9qy5YtSklJCfTFx8eroaEhaNwrr7yi5557TnPmzOlwvaysLG3bti3w2G63d7U0AAAwyHQpsJw9e1a5ubl69dVXtW7dukB/WFiYXC5X0Nji4mLde++9ioqK6nBNu91+yVwAAACpix8JLVmyRHPnzlVGRkaH4yoqKnTkyBEtXLjwimvu27dPY8eOVVJSkhYvXqympqbLjvX7/fL5fEENAAAMXiGfYdmxY4cOHTqkgwcPXnHs1q1bde2112rGjBkdjsvKytL8+fOVkJCgmpoarVy5UnPmzFFZWZnCwsIuGV9YWKg1a9aEWjoAABigbJZlWZ0dfPLkSd100036+OOPA9eu3Hbbbbrxxhu1YcOGoLHfffedYmNj9fTTT+vxxx8Pqagvv/xSkydP1t69e5Wenn7Jcb/fL7/fH3js8/kUHx8vr9crh8MR0s8CAAD9w+fzyel0dur9O6SPhCoqKnT69GlNnz5d4eHhCg8PV2lpqTZu3Kjw8HC1tbUFxu7atUvnzp1TXl5eyBuYNGmSoqOjVV1d3e5xu90uh8MR1AAAwOAV0kdC6enpqqysDOp76KGHlJycrBUrVgR9fLN161bdddddGjNmTMhFnTp1Sk1NTYqNjQ15LgAAGHxCCiwjRozQtGnTgvqGDx+u0aNHB/VXV1dr//79+sMf/tDuOsnJySosLNTdd9+ts2fPas2aNcrJyZHL5VJNTY2WL1+uxMREZWZmdmFLAABgsOmVO92+9tprGjdunGbPnt3u8aqqKnm9Xkk/fBX66NGjuuuuu3TNNddo4cKFSk1N1X//939zLxYAACApxItuTRXKRTsAAMAMvXbRLQAAQH8gsAAAAOMRWAAAgPEILAAAwHgEFgAAYDwCCwAAMB6BBQAAGI/AAgAAjEdgAQAAxiOwAAAA4xFYAACA8QgsAADAeAQWAABgPAILAAAwHoEFAAAYj8ACAACMR2ABAADGI7AAAADjEVgAAIDxCCwAAMB4BBYAAGA8AgsAADAegQUAABiPwAIAAIxHYAEAAMYjsAAAAOMRWAAAgPEILAAAwHgEFgAAYDwCCwAAMF54fxcAABi8Jj71wSV9dUVz+6ESDHTdOsNSVFQkm82mpUuXBvpuu+022Wy2oLZo0aIO17EsS6tXr1ZsbKyGDRumjIwMHT9+vDulAQD6WXthpaN+oCNdDiwHDx7Uli1blJKScsmxhx9+WA0NDYG2fv36Dtdav369Nm7cqM2bN6u8vFzDhw9XZmamWltbu1oeAKAfXSmUEFoQqi4FlrNnzyo3N1evvvqqrr766kuOX3XVVXK5XIHmcDguu5ZlWdqwYYNWrVql7OxspaSkaPv27aqvr9c777zTlfIAAP2os2GE0IJQdCmwLFmyRHPnzlVGRka7x998801FR0dr2rRpKigo0Llz5y67Vm1trTweT9BaTqdTaWlpKisra3eO3++Xz+cLagAAYPAK+aLbHTt26NChQzp48GC7xx944AFNmDBBcXFxOnr0qFasWKGqqiq9/fbb7Y73eDySpJiYmKD+mJiYwLEfKyws1Jo1a0ItHQAADFAhBZaTJ0/q0Ucf1ccff6zIyMh2x+Tn5wf+fP311ys2Nlbp6emqqanR5MmTu1ft/6+goEDLli0LPPb5fIqPj++RtQEAgHlC+kiooqJCp0+f1vTp0xUeHq7w8HCVlpZq48aNCg8PV1tb2yVz0tLSJEnV1dXtrulyuSRJjY2NQf2NjY2BYz9mt9vlcDiCGgAAGLxCCizp6emqrKzUkSNHAu2mm25Sbm6ujhw5orCwsEvmHDlyRJIUGxvb7poJCQlyuVwqKSkJ9Pl8PpWXl8vtdodSHgDAAJ29zwr3Y0EoQgosI0aM0LRp04La8OHDNXr0aE2bNk01NTVau3atKioqVFdXp927dysvL0+33HJL0Nefk5OTVVxcLEmB+7isW7dOu3fvVmVlpfLy8hQXF6d58+b16GYBAH3jSmGEsIJQ9eidbiMiIrR3715t2LBBLS0tio+PV05OjlatWhU0rqqqSl6vN/B4+fLlamlpUX5+vpqbmzVz5kzt2bPnstfJAADMV1c0lzvdosfYLMuy+ruI7vL5fHI6nfJ6vVzPAgDAABHK+ze//BAAABiPwAIAAIxHYAEAAMYjsAAAAOMRWAAAgPEILAAAwHgEFgAAYDwCCwAAMB6BBQAAGI/AAgAAjEdgAQAAxiOwAAAA4xFYAACA8QgsAADAeAQWAABgPAILAAAwHoEFAAAYj8ACAACMR2ABAADGI7AAAADjEVgAAIDxCCwAAMB4BBYAAGA8AgsAADAegQUAABiPwAIAAIxHYAEAAMYjsAAAAOMRWAAAgPEILAAAwHgEFgAAYLxuBZaioiLZbDYtXbpUkvTtt9/qkUceUVJSkoYNG6bx48fr17/+tbxeb4frLFiwQDabLahlZWV1pzQAADCIhHd14sGDB7VlyxalpKQE+urr61VfX6/nn39eU6dO1VdffaVFixapvr5eu3bt6nC9rKwsbdu2LfDYbrd3tTQAADDIdCmwnD17Vrm5uXr11Ve1bt26QP+0adP0+9//PvB48uTJevbZZ/WLX/xCf/3rXxUefvkfZ7fb5XK5ulIOAAAY5Lr0kdCSJUs0d+5cZWRkXHGs1+uVw+HoMKxI0r59+zR27FglJSVp8eLFampquuxYv98vn88X1AAAwOAV8hmWHTt26NChQzp48OAVx37zzTdau3at8vPzOxyXlZWl+fPnKyEhQTU1NVq5cqXmzJmjsrIyhYWFXTK+sLBQa9asCbV0AAAwQNksy7I6O/jkyZO66aab9PHHHweuXbntttt04403asOGDUFjfT6fZs2apVGjRmn37t0aOnRop4v68ssvNXnyZO3du1fp6emXHPf7/fL7/UE/Kz4+PnA2BwAAmM/n88npdHbq/Tukj4QqKip0+vRpTZ8+XeHh4QoPD1dpaak2btyo8PBwtbW1SZLOnDmjrKwsjRgxQsXFxSGFFUmaNGmSoqOjVV1d3e5xu90uh8MR1AAAwOAV0kdC6enpqqysDOp76KGHlJycrBUrVigsLEw+n0+ZmZmy2+3avXu3IiMjQy7q1KlTampqUmxsbMhzAQDA4BPSGZYRI0Zo2rRpQW348OEaPXq0pk2bJp/Pp9mzZ6ulpUVbt26Vz+eTx+ORx+MJnH2RpOTkZBUXF0v64RtHTz75pA4cOKC6ujqVlJQoOztbiYmJyszM7NndAgCAAanL92Fpz6FDh1ReXi5JSkxMDDpWW1uriRMnSpKqqqoCN5MLCwvT0aNH9cYbb6i5uVlxcXGaPXu21q5dy71YAACApBAvujVVKBftAAAAM/TaRbcAAAD9gcACAACMR2ABAADGI7AAAADjEVgAAIDxCCwAAMB4BBYAAGA8AgsAADAegQUAABiPwAIAAIxHYAEAAMYjsAAAAOMRWAAAgPEILAAAwHgEFgAAYDwCCwAAMB6BBQAAGI/AAgAAjEdgAQAAxiOwAAAA4xFYAACA8QgsAADAeAQWAABgPAILAAAwHoEFAAAYj8ACAACMR2ABAADGI7AAAADjEVgAAIDxCCwAAMB44f1dAABczp6DX2vR748EHm/OuVFZ/+//038FAeg33TrDUlRUJJvNpqVLlwb6WltbtWTJEo0ePVpRUVHKyclRY2Njh+tYlqXVq1crNjZWw4YNU0ZGho4fP96d0gAMcBOf+iAorEjSot8f0cSnPuifggD0qy4HloMHD2rLli1KSUkJ6n/sscf03nvvaefOnSotLVV9fb3mz5/f4Vrr16/Xxo0btXnzZpWXl2v48OHKzMxUa2trV8sDMIBdKZQQWoC/P10KLGfPnlVubq5effVVXX311YF+r9errVu36je/+Y3uuOMOpaamatu2bfr000914MCBdteyLEsbNmzQqlWrlJ2drZSUFG3fvl319fV65513urQpAAPXnoNf9+g4AINDlwLLkiVLNHfuXGVkZAT1V1RU6Pvvvw/qT05O1vjx41VWVtbuWrW1tfJ4PEFznE6n0tLSLjvH7/fL5/MFNQCDw48/BuruOACDQ8gX3e7YsUOHDh3SwYMHLznm8XgUERGhkSNHBvXHxMTI4/G0u97F/piYmE7PKSws1Jo1a0ItHQAADFAhnWE5efKkHn30Ub355puKjIzsrZquqKCgQF6vN9BOnjzZb7UAAIDeF1Jgqaio0OnTpzV9+nSFh4crPDxcpaWl2rhxo8LDwxUTE6Pz58+rubk5aF5jY6NcLle7a17s//E3iTqaY7fb5XA4ghqAwWFzzo09Og7A4BBSYElPT1dlZaWOHDkSaDfddJNyc3MDfx46dKhKSkoCc6qqqnTixAm53e5210xISJDL5Qqa4/P5VF5eftk5AAavzt5nhfuxAH9fQrqGZcSIEZo2bVpQ3/DhwzV69OhA/8KFC7Vs2TKNGjVKDodDjzzyiNxut26++ebAnOTkZBUWFuruu+8O3Mdl3bp1mjJlihISEvT0008rLi5O8+bN6/4OAQw4dUVzO/zqcl3R3D6sBoAJevxOty+88IKGDBminJwc+f1+ZWZm6uWXXw4aU1VVJa/XG3i8fPlytbS0KD8/X83NzZo5c6b27NnTr9fJAOhfdUVzudMtgACbZVlWfxfRXT6fT06nU16vl+tZAAAYIEJ5/+aXHwIAAOMRWAAAgPEILAAAwHgEFgAAYDwCCwAAMB6BBQAAGI/AAgAAjEdgAQAAxiOwAAAA4xFYAACA8QgsAADAeAQWAABgPAILAAAwHoEFAAAYj8ACAACMR2ABAADGI7AAAADjEVgAAIDxCCwAAMB4BBYAAGA8AgsAADAegQUAABiPwAIAAIxHYAEAAMYjsAAAAOMRWAAAgPEILAAAwHgEFgAAYDwCCwAAMB6BBQAAGI/AAgAAjBdSYNm0aZNSUlLkcDjkcDjkdrv14YcfSpLq6upks9nabTt37rzsmgsWLLhkfFZWVvd2BQAABpXwUAaPGzdORUVFmjJliizL0htvvKHs7GwdPnxYycnJamhoCBr/yiuv6LnnntOcOXM6XDcrK0vbtm0LPLbb7aGUBQAABrmQAsvPfvazoMfPPvusNm3apAMHDui6666Ty+UKOl5cXKx7771XUVFRHa5rt9svmQsAAHBRl69haWtr044dO9TS0iK3233J8YqKCh05ckQLFy684lr79u3T2LFjlZSUpMWLF6upqanD8X6/Xz6fL6gBAIDBK6QzLJJUWVkpt9ut1tZWRUVFqbi4WFOnTr1k3NatW3XttddqxowZHa6XlZWl+fPnKyEhQTU1NVq5cqXmzJmjsrIyhYWFtTunsLBQa9asCbV0AAAwQNksy7JCmXD+/HmdOHFCXq9Xu3bt0m9/+1uVlpYGhZbvvvtOsbGxevrpp/X444+HVNCXX36pyZMna+/evUpPT293jN/vl9/vDzz2+XyKj4+X1+uVw+EI6ecBAID+4fP55HQ6O/X+HfJHQhEREUpMTFRqaqoKCwt1ww036MUXXwwas2vXLp07d055eXmhLq9JkyYpOjpa1dXVlx1jt9sD31S62AAAwODV7fuwXLhwIehsh/TDx0F33XWXxowZE/J6p06dUlNTk2JjY7tbGgAAGCRCCiwFBQXav3+/6urqVFlZqYKCAu3bt0+5ubmBMdXV1dq/f79+9atftbtGcnKyiouLJUlnz57Vk08+qQMHDqiurk4lJSXKzs5WYmKiMjMzu7EtAAAwmIR00e3p06eVl5enhoYGOZ1OpaSk6KOPPtKsWbMCY1577TWNGzdOs2fPbneNqqoqeb1eSVJYWJiOHj2qN954Q83NzYqLi9Ps2bO1du1a7sUCAAACQr7o1kShXLQDAADM0KsX3QIAAPQ1AgsAADAegQUAABiPwAIAAIxHYAEAAMYjsAAAAOMRWAAAgPEILAAAwHgEFgAAYDwCCwAAMB6BBQAAGI/AAgAAjEdgAQAAxiOwAAAA4xFYAACA8QgsAADAeAQWAABgPAILAAAwHoEFAAAYj8ACAACMR2ABAADGI7AAAADjEVgAAIDxCCwAAMB4BBYAAGA8AgsAADAegQUAABiPwAIAAIxHYAEAAMYjsAAAAOOF93cBQG/60+f/V7/Y/ufA4/+T91PNnDqmHysCAHRFSGdYNm3apJSUFDkcDjkcDrndbn344YeB47fddptsNltQW7RoUYdrWpal1atXKzY2VsOGDVNGRoaOHz/etd0Af2PiUx8EhRVJ+sX2P2viUx/0U0UAgK4KKbCMGzdORUVFqqio0GeffaY77rhD2dnZOnbsWGDMww8/rIaGhkBbv359h2uuX79eGzdu1ObNm1VeXq7hw4crMzNTra2tXdsRIF0xlBBaAGBgCSmw/OxnP9Odd96pKVOm6JprrtGzzz6rqKgoHThwIDDmqquuksvlCjSHw3HZ9SzL0oYNG7Rq1SplZ2crJSVF27dvV319vd55550ubwp/3/70+f/t0XEAgP7X5Ytu29ratGPHDrW0tMjtdgf633zzTUVHR2vatGkqKCjQuXPnLrtGbW2tPB6PMjIyAn1Op1NpaWkqKyu77Dy/3y+fzxfUgIt+/DFQd8cBAPpfyBfdVlZWyu12q7W1VVFRUSouLtbUqVMlSQ888IAmTJiguLg4HT16VCtWrFBVVZXefvvtdtfyeDySpJiYmKD+mJiYwLH2FBYWas2aNaGWDgAABqiQA0tSUpKOHDkir9erXbt26cEHH1RpaammTp2q/Pz8wLjrr79esbGxSk9PV01NjSZPntxjRRcUFGjZsmWBxz6fT/Hx8T22PgAAMEvIHwlFREQoMTFRqampKiws1A033KAXX3yx3bFpaWmSpOrq6naPu1wuSVJjY2NQf2NjY+BYe+x2e+CbShcbcNH/yftpj44DAPS/bt847sKFC/L7/e0eO3LkiCQpNja23eMJCQlyuVwqKSkJ9Pl8PpWXlwddFwOEorP3WeF+LAAwcIQUWAoKCrR//37V1dWpsrJSBQUF2rdvn3Jzc1VTU6O1a9eqoqJCdXV12r17t/Ly8nTLLbcoJSUlsEZycrKKi4slSTabTUuXLtW6deu0e/duVVZWKi8vT3FxcZo3b16PbhR/X+qK5nbrOADALCFdw3L69Gnl5eWpoaFBTqdTKSkp+uijjzRr1iydPHlSe/fu1YYNG9TS0qL4+Hjl5ORo1apVQWtUVVXJ6/UGHi9fvlwtLS3Kz89Xc3OzZs6cqT179igyMrJndoi/W3VFc7nTLQAMEjbLsqz+LqK7fD6fnE6nvF4v17MAADBAhPL+zS8/BAAAxiOwAAAA4xFYAACA8QgsAADAeAQWAABgPAILAAAwHoEFAAAYj8ACAACMR2ABAADGI7AAAADjEVgAAIDxCCwAAMB4BBYAAGA8AgsAADAegQUAABiPwAIAAIxHYAEAAMYjsAAAAOMRWAAAgPEILAAAwHgEFgAAYDwCCwAAMB6BBQAAGI/AAgAAjEdgAQAAxiOwAAAA4xFYAACA8QgsAADAeAQWAABgPAILAAAwHoEFAAAYL6TAsmnTJqWkpMjhcMjhcMjtduvDDz+UJH377bd65JFHlJSUpGHDhmn8+PH69a9/La/X2+GaCxYskM1mC2pZWVld3xEAABh0wkMZPG7cOBUVFWnKlCmyLEtvvPGGsrOzdfjwYVmWpfr6ej3//POaOnWqvvrqKy1atEj19fXatWtXh+tmZWVp27Ztgcd2u71ruwEAAIOSzbIsqzsLjBo1Ss8995wWLlx4ybGdO3fqF7/4hVpaWhQe3n42WrBggZqbm/XOO+90uQafzyen0ymv1yuHw9HldQAAQN8J5f27y9ewtLW1aceOHWppaZHb7W53zMUCLhdWLtq3b5/Gjh2rpKQkLV68WE1NTR2O9/v98vl8QQ0AAAxeIX0kJEmVlZVyu91qbW1VVFSUiouLNXXq1EvGffPNN1q7dq3y8/M7XC8rK0vz589XQkKCampqtHLlSs2ZM0dlZWUKCwtrd05hYaHWrFkTaukAAGCACvkjofPnz+vEiRPyer3atWuXfvvb36q0tDQotPh8Ps2aNUujRo3S7t27NXTo0E6v/+WXX2ry5Mnau3ev0tPT2x3j9/vl9/uDfl58fDwfCQEAMID06kdCERERSkxMVGpqqgoLC3XDDTfoxRdfDBw/c+aMsrKyNGLECBUXF4cUViRp0qRJio6OVnV19WXH2O32wDeVLjYAADB4dfs+LBcuXAic7fD5fJo9e7YiIiK0e/duRUZGhrzeqVOn1NTUpNjY2O6WBgAABomQAktBQYH279+vuro6VVZWqqCgQPv27VNubm4grLS0tGjr1q3y+XzyeDzyeDxqa2sLrJGcnKzi4mJJ0tmzZ/Xkk0/qwIEDqqurU0lJibKzs5WYmKjMzMye3SkAABiwQrro9vTp08rLy1NDQ4OcTqdSUlL00UcfadasWdq3b5/Ky8slSYmJiUHzamtrNXHiRElSVVVV4GZyYWFhOnr0qN544w01NzcrLi5Os2fP1tq1a7kXCwAACOj2fVhMwH1YAAAYePrkPiwAAAB9hcACAACMR2ABAADGI7AAAADjEVgAAIDxCCwAAMB4BBYAAGA8AgsAADAegQUAABiPwAIAAIxHYAEAAMYjsAAAAOMRWAAAgPEILAAAwHgEFgAAYDwCCwAAMB6BBQAAGI/AAgAAjEdgAQAAxiOwAAAA4xFYAACA8QgsAADAeAQWAABgPAILAAAwHoEFAAAYj8ACAACMR2ABAADGI7AAAADjEVgAAIDxCCwAAMB44f1dgMn2HmrQr946FHj823unK2N6bD9WBADA36eQzrBs2rRJKSkpcjgccjgccrvd+vDDDwPHW1tbtWTJEo0ePVpRUVHKyclRY2Njh2talqXVq1crNjZWw4YNU0ZGho4fP9613fSgiU99EBRWJOlXbx3SxKc+6KeKAAD4+xVSYBk3bpyKiopUUVGhzz77THfccYeys7N17NgxSdJjjz2m9957Tzt37lRpaanq6+s1f/78Dtdcv369Nm7cqM2bN6u8vFzDhw9XZmamWltbu76rbrpSKCG0AADQt2yWZVndWWDUqFF67rnndM8992jMmDH6j//4D91zzz2SpC+++ELXXnutysrKdPPNN18y17IsxcXF6fHHH9cTTzwhSfJ6vYqJidHrr7+u++67r1M1+Hw+OZ1Oeb1eORyO7mznko+BLoePhwAA6J5Q3r+7fNFtW1ubduzYoZaWFrndblVUVOj7779XRkZGYExycrLGjx+vsrKydteora2Vx+MJmuN0OpWWlnbZOZLk9/vl8/mCWk/pTFgJZRwAAOi+kANLZWWloqKiZLfbtWjRIhUXF2vq1KnyeDyKiIjQyJEjg8bHxMTI4/G0u9bF/piYmE7PkaTCwkI5nc5Ai4+PD3UbAABgAAk5sCQlJenIkSMqLy/X4sWL9eCDD+rzzz/vjdouq6CgQF6vN9BOnjzZpz8fAAD0rZADS0REhBITE5WamqrCwkLdcMMNevHFF+VyuXT+/Hk1NzcHjW9sbJTL5Wp3rYv9P/4mUUdzJMlutwe+qXSx9ZTf3ju9R8cBAIDu6/aN4y5cuCC/36/U1FQNHTpUJSUlgWNVVVU6ceKE3G53u3MTEhLkcrmC5vh8PpWXl192Tm/r7IW0XHALAEDfCSmwFBQUaP/+/aqrq1NlZaUKCgq0b98+5ebmyul0auHChVq2bJk++eQTVVRU6KGHHpLb7Q76hlBycrKKi4slSTabTUuXLtW6deu0e/duVVZWKi8vT3FxcZo3b16PbjQUdUVzu3UcAAD0rJDudHv69Gnl5eWpoaFBTqdTKSkp+uijjzRr1ixJ0gsvvKAhQ4YoJydHfr9fmZmZevnll4PWqKqqktfrDTxevny5WlpalJ+fr+bmZs2cOVN79uxRZGRkD2yv6+qK5nKnWwAADNHt+7CYoCfvwwIAAPpGn9yHBQAAoK8QWAAAgPEILAAAwHgEFgAAYDwCCwAAMB6BBQAAGI/AAgAAjEdgAQAAxiOwAAAA44V0a35TXbxZr8/n6+dKAABAZ1183+7MTfcHRWA5c+aMJCk+Pr6fKwEAAKE6c+aMnE5nh2MGxe8SunDhgurr6zVixAjZbLb+LqfbfD6f4uPjdfLkyUH3u5EG894k9jfQsb+Bjf0NPJZl6cyZM4qLi9OQIR1fpTIozrAMGTJE48aN6+8yepzD4Rg0/yh/bDDvTWJ/Ax37G9jY38BypTMrF3HRLQAAMB6BBQAAGI/AYiC73a5nnnlGdru9v0vpcYN5bxL7G+jY38DG/ga3QXHRLQAAGNw4wwIAAIxHYAEAAMYjsAAAAOMRWAAAgPEILAa46667NH78eEVGRio2Nla//OUvVV9f3+Gc1tZWLVmyRKNHj1ZUVJRycnLU2NjYRxV3Xl1dnRYuXKiEhAQNGzZMkydP1jPPPKPz5893OO+2226TzWYLaosWLeqjqjuvq/sbKM+fJD377LOaMWOGrrrqKo0cObJTcxYsWHDJ85eVldW7hXZRV/ZnWZZWr16t2NhYDRs2TBkZGTp+/HjvFtpF3377rXJzc+VwODRy5EgtXLhQZ8+e7XCOya+/f//3f9fEiRMVGRmptLQ0/fnPf+5w/M6dO5WcnKzIyEhdf/31+sMf/tBHlYYulL29/vrrlzxHkZGRfVht3yOwGOD222/XW2+9paqqKv3+979XTU2N7rnnng7nPPbYY3rvvfe0c+dOlZaWqr6+XvPnz++jijvviy++0IULF7RlyxYdO3ZML7zwgjZv3qyVK1dece7DDz+shoaGQFu/fn0fVByaru5voDx/knT+/Hn9/Oc/1+LFi0Oal5WVFfT8/e53v+ulCrunK/tbv369Nm7cqM2bN6u8vFzDhw9XZmamWltbe7HSrsnNzdWxY8f08ccf6/3339f+/fuVn59/xXkmvv7+8z//U8uWLdMzzzyjQ4cO6YYbblBmZqZOnz7d7vhPP/1U999/vxYuXKjDhw9r3rx5mjdvnv73f/+3jyu/slD3Jv1wx9u/fY6++uqrPqy4H1gwzrvvvmvZbDbr/Pnz7R5vbm62hg4dau3cuTPQ95e//MWSZJWVlfVVmV22fv16KyEhocMxt956q/Xoo4/2TUE97Er7G6jP37Zt2yyn09mpsQ8++KCVnZ3dq/X0tM7u78KFC5bL5bKee+65QF9zc7Nlt9ut3/3ud71YYeg+//xzS5J18ODBQN+HH35o2Ww26+uvv77sPFNffz/96U+tJUuWBB63tbVZcXFxVmFhYbvj7733Xmvu3LlBfWlpadY//uM/9mqdXRHq3kJ5PQ4WnGExzLfffqs333xTM2bM0NChQ9sdU1FRoe+//14ZGRmBvuTkZI0fP15lZWV9VWqXeb1ejRo16orj3nzzTUVHR2vatGkqKCjQuXPn+qC67rvS/gb689dZ+/bt09ixY5WUlKTFixerqampv0vqEbW1tfJ4PEHPn9PpVFpamnHPX1lZmUaOHKmbbrop0JeRkaEhQ4aovLy8w7mmvf7Onz+vioqKoL/3IUOGKCMj47J/72VlZUHjJSkzM9O456kre5Oks2fPasKECYqPj1d2draOHTvWF+X2m0Hxyw8HgxUrVujf/u3fdO7cOd188816//33LzvW4/EoIiLiks/bY2Ji5PF4ernS7qmurtZLL72k559/vsNxDzzwgCZMmKC4uDgdPXpUK1asUFVVld5+++0+qrRrOrO/gfz8dVZWVpbmz5+vhIQE1dTUaOXKlZozZ47KysoUFhbW3+V1y8XnKCYmJqjfxOfP4/Fo7NixQX3h4eEaNWpUh7Wa+Pr75ptv1NbW1u7f+xdffNHuHI/HMyCep67sLSkpSa+99ppSUlLk9Xr1/PPPa8aMGTp27Nig/GXAEtew9Jqnnnrqkguiftz+9h/ik08+qcOHD+u//uu/FBYWpry8PFkG34Q41P1J0tdff62srCz9/Oc/18MPP9zh+vn5+crMzNT111+v3Nxcbd++XcXFxaqpqenNbQX09v76W1f2F4r77rtPd911l66//nrNmzdP77//vg4ePKh9+/b13CY60Nv762+9vb/+fv3hytxut/Ly8nTjjTfq1ltv1dtvv60xY8Zoy5Yt/V1ar+EMSy95/PHHtWDBgg7HTJo0KfDn6OhoRUdH65prrtG1116r+Ph4HThwQG63+5J5LpdL58+fV3Nzc9D/pTc2NsrlcvXUFjoU6v7q6+t1++23a8aMGXrllVdC/nlpaWmSfjiDMXny5JDnh6o39zcQn7/umjRpkqKjo1VdXa309PQeW/dyenN/F5+jxsZGxcbGBvobGxt14403dmnNUHV2fy6X65KLNv/617/q22+/DenfWl+//toTHR2tsLCwS75N19HrxuVyhTS+v3Rlbz82dOhQ/eQnP1F1dXVvlGgEAksvGTNmjMaMGdOluRcuXJAk+f3+do+npqZq6NChKikpUU5OjiSpqqpKJ06caDfg9IZQ9vf111/r9ttvV2pqqrZt26YhQ0I/sXfkyBFJCnqD6E29ub+B9vz1hFOnTqmpqcnI5y9UCQkJcrlcKikpCQQUn8+n8vLykL9J1VWd3Z/b7VZzc7MqKiqUmpoqSfrjH/+oCxcuBEJIZ/T16689ERERSk1NVUlJiebNmyfph/9WlpSU6J//+Z/bneN2u1VSUqKlS5cG+j7++OM+e511Vlf29mNtbW2qrKzUnXfe2YuV9rP+vur3792BAwesl156yTp8+LBVV1dnlZSUWDNmzLAmT55stba2WpZlWadOnbKSkpKs8vLywLxFixZZ48ePt/74xz9an332meV2uy23291f27isU6dOWYmJiVZ6erp16tQpq6GhIdD+dszf7q+6utr613/9V+uzzz6zamtrrXfffdeaNGmSdcstt/TXNi6rK/uzrIHz/FmWZX311VfW4cOHrTVr1lhRUVHW4cOHrcOHD1tnzpwJjElKSrLefvtty7Is68yZM9YTTzxhlZWVWbW1tdbevXut6dOnW1OmTAn8mzZJqPuzLMsqKiqyRo4cab377rvW0aNHrezsbCshIcH67rvv+mMLHcrKyrJ+8pOfWOXl5daf/vQna8qUKdb9998fOD6QXn87duyw7Ha79frrr1uff/65lZ+fb40cOdLyeDyWZVnWL3/5S+upp54KjP+f//kfKzw83Hr++eetv/zlL9YzzzxjDR061KqsrOyvLVxWqHtbs2aN9dFHH1k1NTVWRUWFdd9991mRkZHWsWPH+msLvY7A0s+OHj1q3X777daoUaMsu91uTZw40Vq0aJF16tSpwJja2lpLkvXJJ58E+r777jvrn/7pn6yrr77auuqqq6y777476E3SFNu2bbMktdsu+vH+Tpw4Yd1yyy2Bv5PExETrySeftLxebz/t4vK6sj/LGjjPn2X98BXl9vb3t/uRZG3bts2yLMs6d+6cNXv2bGvMmDHW0KFDrQkTJlgPP/xw4D+8pgl1f5b1w1ebn376aSsmJsay2+1Wenq6VVVV1ffFd0JTU5N1//33W1FRUZbD4bAeeuihoDA20F5/L730kjV+/HgrIiLC+ulPf2odOHAgcOzWW2+1HnzwwaDxb731lnXNNddYERER1nXXXWd98MEHfVxx54Wyt6VLlwbGxsTEWHfeead16NChfqi679gsy+ArOwEAAMS3hAAAwABAYAEAAMYjsAAAAOMRWAAAgPEILAAAwHgEFgAAYDwCCwAAMB6BBQAAGI/AAgAAjEdgAQAAxiOwAAAA4xFYAACA8f4/xcjZorMsDKUAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Standardize features by removing the mean and scaling to unit variance.\n",
        "\n",
        "The standard score of a sample x is calculated as:\n",
        "\n",
        "z = (x - u) / s\n",
        "\n",
        "where u is the mean of the training samples or zero if with_mean=False, and s is the standard deviation of the training samples or one if with_std=False.\n",
        "\n",
        "Centering and scaling happen independently on each feature by computing the relevant statistics on the samples in the training set. Mean and standard deviation are then stored to be used on later data using transform.\n",
        "\n",
        "Standardization of a dataset is a common requirement for many machine learning estimators: they might behave badly if the individual features do not more or less look like standard normally distributed data (e.g. Gaussian with 0 mean and unit variance).\n",
        "\n",
        "For instance many elements used in the objective function of a learning algorithm (such as the RBF kernel of Support Vector Machines or the L1 and L2 regularizers of linear models) assume that all features are centered around 0 and have variance in the same order. If a feature has a variance that is orders of magnitude larger than others, it might dominate the objective function and make the estimator unable to learn from other features correctly as expected."
      ],
      "metadata": {
        "id": "T7Ew_h6A2pJn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(X_train[:,3])\n",
        "plt.hist(X_train_scaled[:,3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "cz3JPJvV2cVI",
        "outputId": "169a6635-be20-401c-eb69-4d197d7188f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 25.,   0.,  21.,   0.,   0.,  27.,   0., 243.,   0., 279.]),\n",
              " array([-3.25610862, -2.85248682, -2.44886502, -2.04524322, -1.64162143,\n",
              "        -1.23799963, -0.83437783, -0.43075604, -0.02713424,  0.37648756,\n",
              "         0.78010936]),\n",
              " <BarContainer object of 10 artists>)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGdCAYAAAA44ojeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAeRUlEQVR4nO3de3BU5f3H8U8uZLkmMWCySQkxXgGBaAPEHS+lkiEEhkrNH2JTRcvAaDeOEOslHQXETkOpoxYnQju1pM4YUToFh9SmxiCh1oAQZbjZDDBpgyWbtDJkIUoI5Pz+cDg/V0DdsLjfxPdr5szsnvPk7LPPUPues2eTGMdxHAEAABgSG+0JAAAAfBGBAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHPioz2B3ujp6dHhw4c1bNgwxcTERHs6AADga3AcR8eOHVNGRoZiY7/8GkmfDJTDhw8rMzMz2tMAAAC9cOjQIY0cOfJLx/TJQBk2bJikz95gYmJilGcDAAC+jmAwqMzMTPf/x79MnwyUMx/rJCYmEigAAPQxX+f2DG6SBQAA5hAoAADAHAIFAACYQ6AAAABzCBQAAGAOgQIAAMwhUAAAgDkECgAAMIdAAQAA5hAoAADAHAIFAACYQ6AAAABzCBQAAGAOgQIAAMyJj/YE8DlLk77wvCM68wAA9GmXPfaXCz7Hv5bPjMBMeo8rKAAAwBwCBQAAmEOgAAAAcwgUAABgDoECAADMIVAAAIA5BAoAADCHQAEAAOYQKAAAwBwCBQAAmEOgAAAAcwgUAABgDoECAADMIVAAAIA5BAoAADCHQAEAAOYQKAAAwBwCBQAAmEOgAAAAcwgUAABgDoECAADMIVAAAIA5BAoAADCHQAEAAOYQKAAAwBwCBQAAmEOgAAAAcwgUAABgDoECAADMIVAAAIA5BAoAADCHQAEAAOaEFSjl5eWaNGmShg0bptTUVM2ePVtNTU0hY6ZMmaKYmJiQ7b777gsZ09LSopkzZ2rw4MFKTU3Vww8/rFOnTl34uwEAAP1CfDiD6+vr5ff7NWnSJJ06dUo///nPNW3aNO3bt09Dhgxxx82fP1/Lli1znw8ePNh9fPr0ac2cOVNer1fvvvuuWltbdffdd2vAgAH65S9/GYG3BAAA+rqwAqWmpibkeWVlpVJTU9XY2KhbbrnF3T948GB5vd5znuPNN9/Uvn379NZbbyktLU3XXXednnrqKT366KNaunSpEhISevE2AABAf3JB96B0dHRIklJSUkL2v/zyyxoxYoTGjRunsrIyffLJJ+6xhoYGjR8/Xmlpae6+goICBYNB7d2795yv09XVpWAwGLIBAID+K6wrKJ/X09OjhQsX6sYbb9S4cePc/T/60Y+UlZWljIwM7dq1S48++qiampr05z//WZIUCARC4kSS+zwQCJzztcrLy/Xkk0/2dqoAAKCP6XWg+P1+7dmzR++8807I/gULFriPx48fr/T0dE2dOlUHDx7UFVdc0avXKisrU2lpqfs8GAwqMzOzdxMHAADm9eojnpKSElVXV+vtt9/WyJEjv3RsXl6eJOnAgQOSJK/Xq7a2tpAxZ56f774Vj8ejxMTEkA0AAPRfYQWK4zgqKSnR+vXrtWnTJmVnZ3/lz+zcuVOSlJ6eLkny+XzavXu32tvb3TG1tbVKTEzU2LFjw5kOAADop8L6iMfv96uqqkqvv/66hg0b5t4zkpSUpEGDBungwYOqqqrSjBkzNHz4cO3atUuLFi3SLbfcogkTJkiSpk2bprFjx+quu+7SihUrFAgE9Pjjj8vv98vj8UT+HQIAgD4nrCsoq1atUkdHh6ZMmaL09HR3e/XVVyVJCQkJeuuttzRt2jSNHj1aDz30kIqKirRx40b3HHFxcaqurlZcXJx8Pp9+/OMf6+677w75vSkAAODbLawrKI7jfOnxzMxM1dfXf+V5srKy9MYbb4Tz0gAA4FuEv8UDAADMIVAAAIA5vf49KLgAS5M+97gjevMAAETUZY/95YLP8a/lMyMwk76PKygAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMCcsAKlvLxckyZN0rBhw5SamqrZs2erqakpZMyJEyfk9/s1fPhwDR06VEVFRWprawsZ09LSopkzZ2rw4MFKTU3Vww8/rFOnTl34uwEAAP1CWIFSX18vv9+vrVu3qra2Vt3d3Zo2bZo6OzvdMYsWLdLGjRu1bt061dfX6/Dhw7r99tvd46dPn9bMmTN18uRJvfvuu/rjH/+oyspKLV68OHLvCgAA9Gnx4QyuqakJeV5ZWanU1FQ1NjbqlltuUUdHh1588UVVVVXp1ltvlSStWbNGY8aM0datW3XDDTfozTff1L59+/TWW28pLS1N1113nZ566ik9+uijWrp0qRISEiL37gAAQJ90QfegdHR0SJJSUlIkSY2Njeru7lZ+fr47ZvTo0Ro1apQaGhokSQ0NDRo/frzS0tLcMQUFBQoGg9q7d+85X6erq0vBYDBkAwAA/VevA6Wnp0cLFy7UjTfeqHHjxkmSAoGAEhISlJycHDI2LS1NgUDAHfP5ODlz/MyxcykvL1dSUpK7ZWZm9nbaAACgD+h1oPj9fu3Zs0dr166N5HzOqaysTB0dHe526NChi/6aAAAgesK6B+WMkpISVVdXa8uWLRo5cqS73+v16uTJkzp69GjIVZS2tjZ5vV53zHvvvRdyvjPf8jkz5os8Ho88Hk9vpgoAAPqgsK6gOI6jkpISrV+/Xps2bVJ2dnbI8dzcXA0YMEB1dXXuvqamJrW0tMjn80mSfD6fdu/erfb2dndMbW2tEhMTNXbs2At5LwAAoJ8I6wqK3+9XVVWVXn/9dQ0bNsy9ZyQpKUmDBg1SUlKS5s2bp9LSUqWkpCgxMVEPPPCAfD6fbrjhBknStGnTNHbsWN11111asWKFAoGAHn/8cfn9fq6SAAAASWEGyqpVqyRJU6ZMCdm/Zs0a3XPPPZKkZ599VrGxsSoqKlJXV5cKCgr0wgsvuGPj4uJUXV2t+++/Xz6fT0OGDNHcuXO1bNmyC3snAACg3wgrUBzH+coxAwcOVEVFhSoqKs47JisrS2+88UY4Lw0AAL5F+Fs8AADAHAIFAACYQ6AAAABzCBQAAGAOgQIAAMwhUAAAgDkECgAAMIdAAQAA5hAoAADAHAIFAACYQ6AAAABzCBQAAGAOgQIAAMwhUAAAgDkECgAAMIdAAQAA5hAoAADAHAIFAACYQ6AAAABzCBQAAGAOgQIAAMwhUAAAgDkECgAAMIdAAQAA5hAoAADAHAIFAACYQ6AAAABzCBQAAGAOgQIAAMwhUAAAgDkECgAAMIdAAQAA5hAoAADAHAIFAACYQ6AAAABzCBQAAGAOgQIAAMwhUAAAgDkECgAAMIdAAQAA5hAoAADAHAIFAACYQ6AAAABzCBQAAGAOgQIAAMwhUAAAgDkECgAAMIdAAQAA5hAoAADAHAIFAACYQ6AAAABzCBQAAGBO2IGyZcsWzZo1SxkZGYqJidGGDRtCjt9zzz2KiYkJ2aZPnx4y5siRIyouLlZiYqKSk5M1b948HT9+/ILeCAAA6D/CDpTOzk7l5OSooqLivGOmT5+u1tZWd3vllVdCjhcXF2vv3r2qra1VdXW1tmzZogULFoQ/ewAA0C/Fh/sDhYWFKiws/NIxHo9HXq/3nMc+/PBD1dTUaPv27Zo4caIk6fnnn9eMGTP09NNPKyMjI9wpAQCAfuai3IOyefNmpaam6pprrtH999+vjz/+2D3W0NCg5ORkN04kKT8/X7Gxsdq2bds5z9fV1aVgMBiyAQCA/ivigTJ9+nS99NJLqqur069+9SvV19ersLBQp0+fliQFAgGlpqaG/Ex8fLxSUlIUCATOec7y8nIlJSW5W2ZmZqSnDQAADAn7I56vMmfOHPfx+PHjNWHCBF1xxRXavHmzpk6d2qtzlpWVqbS01H0eDAaJFAAA+rGL/jXjyy+/XCNGjNCBAwckSV6vV+3t7SFjTp06pSNHjpz3vhWPx6PExMSQDQAA9F8XPVA++ugjffzxx0pPT5ck+Xw+HT16VI2Nje6YTZs2qaenR3l5eRd7OgAAoA8I+yOe48ePu1dDJKm5uVk7d+5USkqKUlJS9OSTT6qoqEher1cHDx7UI488oiuvvFIFBQWSpDFjxmj69OmaP3++Vq9ere7ubpWUlGjOnDl8gwcAAEjqxRWUHTt26Prrr9f1118vSSotLdX111+vxYsXKy4uTrt27dIPfvADXX311Zo3b55yc3P197//XR6Pxz3Hyy+/rNGjR2vq1KmaMWOGbrrpJv3ud7+L3LsCAAB9WthXUKZMmSLHcc57/G9/+9tXniMlJUVVVVXhvjQAAPiW4G/xAAAAcwgUAABgDoECAADMIVAAAIA5BAoAADCHQAEAAOYQKAAAwBwCBQAAmEOgAAAAcwgUAABgDoECAADMIVAAAIA5BAoAADCHQAEAAOYQKAAAwBwCBQAAmEOgAAAAcwgUAABgDoECAADMIVAAAIA5BAoAADCHQAEAAOYQKAAAwBwCBQAAmEOgAAAAcwgUAABgDoECAADMIVAAAIA5BAoAADCHQAEAAOYQKAAAwBwCBQAAmEOgAAAAcwgUAABgDoECAADMIVAAAIA5BAoAADCHQAEAAOYQKAAAwBwCBQAAmEOgAAAAcwgUAABgDoECAADMIVAAAIA5BAoAADCHQAEAAOYQKAAAwBwCBQAAmEOgAAAAcwgUAABgDoECAADMIVAAAIA5YQfKli1bNGvWLGVkZCgmJkYbNmwIOe44jhYvXqz09HQNGjRI+fn52r9/f8iYI0eOqLi4WImJiUpOTta8efN0/PjxC3ojAACg/wg7UDo7O5WTk6OKiopzHl+xYoVWrlyp1atXa9u2bRoyZIgKCgp04sQJd0xxcbH27t2r2tpaVVdXa8uWLVqwYEHv3wUAAOhX4sP9gcLCQhUWFp7zmOM4eu655/T444/rtttukyS99NJLSktL04YNGzRnzhx9+OGHqqmp0fbt2zVx4kRJ0vPPP68ZM2bo6aefVkZGxgW8HQAA0B9E9B6U5uZmBQIB5efnu/uSkpKUl5enhoYGSVJDQ4OSk5PdOJGk/Px8xcbGatu2bec8b1dXl4LBYMgGAAD6r4gGSiAQkCSlpaWF7E9LS3OPBQIBpaamhhyPj49XSkqKO+aLysvLlZSU5G6ZmZmRnDYAADCmT3yLp6ysTB0dHe526NChaE8JAABcRBENFK/XK0lqa2sL2d/W1uYe83q9am9vDzl+6tQpHTlyxB3zRR6PR4mJiSEbAADovyIaKNnZ2fJ6vaqrq3P3BYNBbdu2TT6fT5Lk8/l09OhRNTY2umM2bdqknp4e5eXlRXI6AACgjwr7WzzHjx/XgQMH3OfNzc3auXOnUlJSNGrUKC1cuFC/+MUvdNVVVyk7O1tPPPGEMjIyNHv2bEnSmDFjNH36dM2fP1+rV69Wd3e3SkpKNGfOHL7BAwAAJPUiUHbs2KHvf//77vPS0lJJ0ty5c1VZWalHHnlEnZ2dWrBggY4ePaqbbrpJNTU1GjhwoPszL7/8skpKSjR16lTFxsaqqKhIK1eujMDbAQAA/UHYgTJlyhQ5jnPe4zExMVq2bJmWLVt23jEpKSmqqqoK96UBAMC3RJ/4Fg8AAPh2IVAAAIA5BAoAADCHQAEAAOYQKAAAwBwCBQAAmEOgAAAAcwgUAABgDoECAADMIVAAAIA5BAoAADCHQAEAAOYQKAAAwBwCBQAAmEOgAAAAcwgUAABgDoECAADMIVAAAIA5BAoAADCHQAEAAOYQKAAAwBwCBQAAmEOgAAAAcwgUAABgDoECAADMIVAAAIA5BAoAADCHQAEAAOYQKAAAwBwCBQAAmEOgAAAAcwgUAABgDoECAADMIVAAAIA5BAoAADCHQAEAAOYQKAAAwBwCBQAAmEOgAAAAcwgUAABgDoECAADMIVAAAIA5BAoAADCHQAEAAOYQKAAAwBwCBQAAmEOgAAAAcwgUAABgDoECAADMIVAAAIA5BAoAADCHQAEAAOZEPFCWLl2qmJiYkG306NHu8RMnTsjv92v48OEaOnSoioqK1NbWFulpAACAPuyiXEG59tpr1dra6m7vvPOOe2zRokXauHGj1q1bp/r6eh0+fFi33377xZgGAADoo+Ivyknj4+X1es/a39HRoRdffFFVVVW69dZbJUlr1qzRmDFjtHXrVt1www0XYzoAAKCPuShXUPbv36+MjAxdfvnlKi4uVktLiySpsbFR3d3dys/Pd8eOHj1ao0aNUkNDw3nP19XVpWAwGLIBAID+K+KBkpeXp8rKStXU1GjVqlVqbm7WzTffrGPHjikQCCghIUHJyckhP5OWlqZAIHDec5aXlyspKcndMjMzIz1tAABgSMQ/4iksLHQfT5gwQXl5ecrKytJrr72mQYMG9eqcZWVlKi0tdZ8Hg0EiBQCAfuyif804OTlZV199tQ4cOCCv16uTJ0/q6NGjIWPa2trOec/KGR6PR4mJiSEbAADovy56oBw/flwHDx5Uenq6cnNzNWDAANXV1bnHm5qa1NLSIp/Pd7GnAgAA+oiIf8Tzs5/9TLNmzVJWVpYOHz6sJUuWKC4uTnfeeaeSkpI0b948lZaWKiUlRYmJiXrggQfk8/n4Bg8AAHBFPFA++ugj3Xnnnfr444916aWX6qabbtLWrVt16aWXSpKeffZZxcbGqqioSF1dXSooKNALL7wQ6WkAAIA+LOKBsnbt2i89PnDgQFVUVKiioiLSLw0AAPoJ/hYPAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYE58tCfQby1N+tzjjujNAwC+BS577C8XfI5/LZ8ZgZkgUriCAgAAzCFQAACAOXzEcy58PAPgIuLjCOCrcQUFAACYQ6AAAABzCBQAAGAOgQIAAMzhJtlwfP7mWYkbaAH0adysC8u4ggIAAMwhUAAAgDkECgAAMIdAAQAA5hAoAADAHAIFAACYQ6AAAABzCBQAAGAOgQIAAMwhUAAAgDkECgAAMIdAAQAA5hAoAADAHAIFAACYQ6AAAABzCBQAAGAOgQIAAMwhUAAAgDkECgAAMIdAAQAA5hAoAADAnKgGSkVFhS677DINHDhQeXl5eu+996I5HQAAYETUAuXVV19VaWmplixZovfff185OTkqKChQe3t7tKYEAACMiFqgPPPMM5o/f77uvfdejR07VqtXr9bgwYP1hz/8IVpTAgAARsRH40VPnjypxsZGlZWVuftiY2OVn5+vhoaGs8Z3dXWpq6vLfd7R0SFJCgaDF2eCXc7/P/78a3x+/xePfd1zROr8APqsnq5PLvgckfjvn5V5RIKV98I8vt45Hcf5ipGfDfrG/ec//3EkOe+++27I/ocfftiZPHnyWeOXLFniSGJjY2NjY2PrB9uhQ4e+shWicgUlXGVlZSotLXWf9/T06MiRIxo+fLhiYmKiOLMLEwwGlZmZqUOHDikxMTHa0+kXWNPIY00ji/WMPNY08i7WmjqOo2PHjikjI+Mrx0YlUEaMGKG4uDi1tbWF7G9ra5PX6z1rvMfjkcfjCdmXnJx8Maf4jUpMTOR/VBHGmkYeaxpZrGfksaaRdzHWNCkp6WuNi8pNsgkJCcrNzVVdXZ27r6enR3V1dfL5fNGYEgAAMCRqH/GUlpZq7ty5mjhxoiZPnqznnntOnZ2duvfee6M1JQAAYETUAuWOO+7Qf//7Xy1evFiBQEDXXXedampqlJaWFq0pfeM8Ho+WLFly1sdX6D3WNPJY08hiPSOPNY08C2sa4zhf57s+AAAA3xz+Fg8AADCHQAEAAOYQKAAAwBwCBQAAmEOgRFFFRYUuu+wyDRw4UHl5eXrvvfeiPaU+Y8uWLZo1a5YyMjIUExOjDRs2hBx3HEeLFy9Wenq6Bg0apPz8fO3fvz86k+0DysvLNWnSJA0bNkypqamaPXu2mpqaQsacOHFCfr9fw4cP19ChQ1VUVHTWL1vE/1u1apUmTJjg/qIrn8+nv/71r+5x1vPCLF++XDExMVq4cKG7jzUNz9KlSxUTExOyjR492j0e7fUkUKLk1VdfVWlpqZYsWaL3339fOTk5KigoUHt7e7Sn1id0dnYqJydHFRUV5zy+YsUKrVy5UqtXr9a2bds0ZMgQFRQU6MSJE9/wTPuG+vp6+f1+bd26VbW1teru7ta0adPU2dnpjlm0aJE2btyodevWqb6+XocPH9btt98exVnbNnLkSC1fvlyNjY3asWOHbr31Vt12223au3evJNbzQmzfvl2//e1vNWHChJD9rGn4rr32WrW2trrbO++84x6L+npG5K//IWyTJ092/H6/+/z06dNORkaGU15eHsVZ9U2SnPXr17vPe3p6HK/X6/z617929x09etTxeDzOK6+8EoUZ9j3t7e2OJKe+vt5xnM/Wb8CAAc66devcMR9++KEjyWloaIjWNPucSy65xPn973/Pel6AY8eOOVdddZVTW1vrfO9733MefPBBx3H4N9obS5YscXJycs55zMJ6cgUlCk6ePKnGxkbl5+e7+2JjY5Wfn6+GhoYozqx/aG5uViAQCFnfpKQk5eXlsb5fU0dHhyQpJSVFktTY2Kju7u6QNR09erRGjRrFmn4Np0+f1tq1a9XZ2Smfz8d6XgC/36+ZM2eGrJ3Ev9He2r9/vzIyMnT55ZeruLhYLS0tkmysZ5/4a8b9zf/+9z+dPn36rN+am5aWpn/+859RmlX/EQgEJOmc63vmGM6vp6dHCxcu1I033qhx48ZJ+mxNExISzvojnazpl9u9e7d8Pp9OnDihoUOHav369Ro7dqx27tzJevbC2rVr9f7772v79u1nHePfaPjy8vJUWVmpa665Rq2trXryySd18803a8+ePSbWk0ABEMLv92vPnj0hn0Wjd6655hrt3LlTHR0d+tOf/qS5c+eqvr4+2tPqkw4dOqQHH3xQtbW1GjhwYLSn0y8UFha6jydMmKC8vDxlZWXptdde06BBg6I4s8/wEU8UjBgxQnFxcWfdDd3W1iav1xulWfUfZ9aQ9Q1fSUmJqqur9fbbb2vkyJHufq/Xq5MnT+ro0aMh41nTL5eQkKArr7xSubm5Ki8vV05Ojn7zm9+wnr3Q2Nio9vZ2ffe731V8fLzi4+NVX1+vlStXKj4+XmlpaazpBUpOTtbVV1+tAwcOmPg3SqBEQUJCgnJzc1VXV+fu6+npUV1dnXw+XxRn1j9kZ2fL6/WGrG8wGNS2bdtY3/NwHEclJSVav369Nm3apOzs7JDjubm5GjBgQMiaNjU1qaWlhTUNQ09Pj7q6uljPXpg6dap2796tnTt3utvEiRNVXFzsPmZNL8zx48d18OBBpaen2/g3+o3ciouzrF271vF4PE5lZaWzb98+Z8GCBU5ycrITCASiPbU+4dixY84HH3zgfPDBB44k55lnnnE++OAD59///rfjOI6zfPlyJzk52Xn99dedXbt2ObfddpuTnZ3tfPrpp1GeuU3333+/k5SU5GzevNlpbW11t08++cQdc9999zmjRo1yNm3a5OzYscPx+XyOz+eL4qxte+yxx5z6+nqnubnZ2bVrl/PYY485MTExzptvvuk4DusZCZ//Fo/jsKbheuihh5zNmzc7zc3Nzj/+8Q8nPz/fGTFihNPe3u44TvTXk0CJoueff94ZNWqUk5CQ4EyePNnZunVrtKfUZ7z99tuOpLO2uXPnOo7z2VeNn3jiCSctLc3xeDzO1KlTnaampuhO2rBzraUkZ82aNe6YTz/91PnpT3/qXHLJJc7gwYOdH/7wh05ra2v0Jm3cT37yEycrK8tJSEhwLr30Umfq1KlunDgO6xkJXwwU1jQ8d9xxh5Oenu4kJCQ43/nOd5w77rjDOXDggHs82usZ4ziO881cqwEAAPh6uAcFAACYQ6AAAABzCBQAAGAOgQIAAMwhUAAAgDkECgAAMIdAAQAA5hAoAADAHAIFAACYQ6AAAABzCBQAAGAOgQIAAMz5P255vcUpO/8vAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5U8Xk6olOkCm"
      },
      "outputs": [],
      "source": [
        "#kombinasi epoch dan nodes 10 50 100 150 200 250 \n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.layers import Dense\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load the data\n",
        "data = df\n",
        "\n",
        "# Preprocess the data\n",
        "X = data.iloc[:, :-1].values #data input\n",
        "y = data.iloc[:, -1].values #data output\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "#define number of nodes \n",
        "num_nodes_list = [10, 50, 100, 150, 200, 250]\n",
        "\n",
        "best_input_node = 0\n",
        "best_mse = float('inf')\n",
        "\n",
        "for num_nodes in num_nodes_list :\n",
        "    \n",
        "    # Create the deep learning model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(units= num_nodes, input_dim=5, activation='relu')) #input layer, how \n",
        "    model.add(Dense(units= 10, activation='relu'))   #hidden layer 1\n",
        "    model.add(Dense(units=1, activation='relu'))   #output layer\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(X_train_scaled, y_train, batch_size=10, epochs=10, verbose = 0)\n",
        "\n",
        "    # Evaluate the model\n",
        "    score = model.evaluate(X_test_scaled, y_test)\n",
        "    print('Test loss for {} nodes: {}'.format(num_nodes, score))\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "    # calculate the mean squared error\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    print(\"Mean Squared Error for {} nodes: {:.4f}\".format(num_nodes, mse))\n",
        "    \n",
        "    if mse < best_mse :\n",
        "        best_mse = mse\n",
        "        best_input_node = num_nodes\n",
        "\n",
        "    # mengekstrak eppoct dan mse dari history\n",
        "    epoch = np.arange(1, len(history.history['loss']) + 1) \n",
        "    mse = history.history['loss'] #Create a pandas dataframe to store the epoch and MSE \n",
        "\n",
        "    df_history = pd.DataFrame({'Epoch': epoch, 'MSE': mse})\n",
        "\n",
        "    #saving\n",
        "    filename = 'training_history_{}nodes.csv'.format(num_nodes)\n",
        "    df_history.to_csv(filename, index = False)\n",
        "    \n",
        "print(f'Best best_input_node : {best_input_node}, mse : {best_mse}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUlfQ269OkCq",
        "outputId": "dcc87be6-928b-4045-fc22-8bf4023008b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0215\n",
            "Test loss for 10 nodes: 0.02151898480951786\n",
            "5/5 [==============================] - 0s 4ms/step\n",
            "Mean Squared Error for 10 nodes: 0.0215\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0202\n",
            "Test loss for 50 nodes: 0.02015514299273491\n",
            "5/5 [==============================] - 0s 3ms/step\n",
            "Mean Squared Error for 50 nodes: 0.0202\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0162\n",
            "Test loss for 100 nodes: 0.01618487574160099\n",
            "5/5 [==============================] - 0s 2ms/step\n",
            "Mean Squared Error for 100 nodes: 0.0162\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0228\n",
            "Test loss for 150 nodes: 0.022825954481959343\n",
            "5/5 [==============================] - 0s 3ms/step\n",
            "Mean Squared Error for 150 nodes: 0.0228\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0281\n",
            "Test loss for 200 nodes: 0.02812470681965351\n",
            "5/5 [==============================] - 0s 3ms/step\n",
            "Mean Squared Error for 200 nodes: 0.0281\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0327\n",
            "Test loss for 250 nodes: 0.03268682584166527\n",
            "5/5 [==============================] - 0s 3ms/step\n",
            "Mean Squared Error for 250 nodes: 0.0327\n",
            "Best best_node: 100, mse : 0.016184876340931426\n"
          ]
        }
      ],
      "source": [
        "#kombinasi epoch dan nodes 10 50 100 150 200 250 \n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.layers import Dense\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load the data\n",
        "data = df\n",
        "\n",
        "# Preprocess the data\n",
        "X = data.iloc[:, :-1].values #data input\n",
        "y = data.iloc[:, -1].values #data output\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "#define number of nodes \n",
        "num_nodes_list = [10, 50, 100, 150, 200, 250]\n",
        "\n",
        "best_node = 0\n",
        "best_mse = float('inf')\n",
        "\n",
        "for num_nodes in num_nodes_list :\n",
        "    \n",
        "    # Create the deep learning model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(units= best_input_node, input_dim=5, activation='relu')) #input layer\n",
        "    model.add(Dense(units=num_nodes, activation='relu'))   #hidden layer 1\n",
        "    model.add(Dense(units=1, activation='relu'))   #output layer\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(X_train_scaled, y_train, batch_size=10, epochs=10, verbose = 0)\n",
        "\n",
        "    # Evaluate the model\n",
        "    score = model.evaluate(X_test_scaled, y_test)\n",
        "    print('Test loss for {} nodes: {}'.format(num_nodes, score))\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "    # calculate the mean squared error\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    print(\"Mean Squared Error for {} nodes: {:.4f}\".format(num_nodes, mse))\n",
        "    \n",
        "    if mse < best_mse :\n",
        "        best_mse = mse\n",
        "        best_node = num_nodes\n",
        "\n",
        "    # mengekstrak eppoct dan mse dari history\n",
        "    epoch = np.arange(1, len(history.history['loss']) + 1) \n",
        "    mse = history.history['loss'] #Create a pandas dataframe to store the epoch and MSE \n",
        "\n",
        "    df_history = pd.DataFrame({'Epoch': epoch, 'MSE': mse})\n",
        "\n",
        "    #saving\n",
        "    filename = 'training_history_{}nodes.csv'.format(num_nodes)\n",
        "    df_history.to_csv(filename, index = False)\n",
        "    \n",
        "print(f'Best best_node: {best_node}, mse : {best_mse}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DK2glaNrOkCs",
        "outputId": "c07e0b61-2b04-4e05-9c5b-86f697090514",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0189\n",
            "Test loss for 1 layers: 0.01885550282895565\n",
            "5/5 [==============================] - 0s 3ms/step\n",
            "Mean Squared Error for 1 layers: 0.0189\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0330\n",
            "Test loss for 2 layers: 0.03299711272120476\n",
            "5/5 [==============================] - 0s 2ms/step\n",
            "Mean Squared Error for 2 layers: 0.0330\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0212\n",
            "Test loss for 3 layers: 0.021240640431642532\n",
            "5/5 [==============================] - 0s 3ms/step\n",
            "Mean Squared Error for 3 layers: 0.0212\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0215\n",
            "Test loss for 4 layers: 0.021495042368769646\n",
            "5/5 [==============================] - 0s 3ms/step\n",
            "Mean Squared Error for 4 layers: 0.0215\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0120\n",
            "Test loss for 5 layers: 0.011994820088148117\n",
            "5/5 [==============================] - 0s 3ms/step\n",
            "Mean Squared Error for 5 layers: 0.0120\n",
            "Best hidden_layer: 5, mse : 0.011994819573854844\n"
          ]
        }
      ],
      "source": [
        "#number of hidden layer dari 1 hingga 5 ( 1, 2, 3, 4, 5)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.layers import Dense\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load the data\n",
        "data = df\n",
        "\n",
        "# Preprocess the data\n",
        "X = data.iloc[:, :-1].values #data input\n",
        "y = data.iloc[:, -1].values #data output\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "#define number of nodes \n",
        "num_layers_list = [1, 2, 3, 4, 5]\n",
        "\n",
        "best_mse = float('inf')\n",
        "best_hidden_layer = 0\n",
        "\n",
        "for num_layers in num_layers_list :\n",
        "    \n",
        "    # Create the deep learning model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(units= best_input_node , input_dim=5, activation='relu')) #input layer\n",
        "    for i in range (num_layers):\n",
        "        model.add(Dense(units=best_node, activation='relu'))   #hidden layer 1\n",
        "    model.add(Dense(units=1, activation='relu'))   #output layer\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(X_train_scaled, y_train, batch_size=10, epochs=10, verbose = 0)\n",
        "\n",
        "    # Evaluate the model\n",
        "    score = model.evaluate(X_test_scaled, y_test)\n",
        "    print('Test loss for {} layers: {}'.format(num_layers, score))\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "    # calculate the mean squared error\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    print(\"Mean Squared Error for {} layers: {:.4f}\".format(num_layers, mse))\n",
        "    \n",
        "    # Check if the current epoch gives a lower loss\n",
        "    if mse < best_mse:\n",
        "        best_mse = mse\n",
        "        best_hidden_layer = num_layers\n",
        "\n",
        "    # mengekstrak eppoct dan mse dari history\n",
        "    epoch = np.arange(1, len(history.history['loss']) + 1) \n",
        "    mse = history.history['loss'] #Create a pandas dataframe to store the epoch and MSE \n",
        "\n",
        "    # print(f\"this is me just checking mse: {mse}\")\n",
        "    df_history = pd.DataFrame({'Epoch': epoch, 'MSE': mse})\n",
        "    \n",
        "    #saving\n",
        "    filename = 'training_history_{}layers.csv'.format(num_layers)\n",
        "\n",
        "    df_history.to_csv(filename, index = False)\n",
        "    \n",
        "print(f'Best hidden_layer: {best_hidden_layer}, mse : {best_mse}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfPOjYhLOkCu",
        "outputId": "943ca803-9ac3-478d-ffbe-d65f8ba256a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training for 1000 epochs\n",
            "Test loss: 0.002525267656892538\n",
            "5/5 [==============================] - 0s 3ms/step\n",
            "Mean Squared Error for 1000 epoch: 0.0025\n",
            "Training for 2000 epochs\n",
            "Test loss: 0.0024182714987546206\n",
            "5/5 [==============================] - 0s 3ms/step\n",
            "Mean Squared Error for 2000 epoch: 0.0024\n",
            "Training for 3000 epochs\n",
            "Test loss: 0.0023997873067855835\n",
            "5/5 [==============================] - 0s 4ms/step\n",
            "Mean Squared Error for 3000 epoch: 0.0024\n",
            "Training for 4000 epochs\n",
            "Test loss: 0.002290532924234867\n",
            "5/5 [==============================] - 0s 3ms/step\n",
            "Mean Squared Error for 4000 epoch: 0.0023\n",
            "Training for 5000 epochs\n",
            "Test loss: 0.0022382375318557024\n",
            "5/5 [==============================] - 0s 2ms/step\n",
            "Mean Squared Error for 5000 epoch: 0.0022\n",
            "Best epoch: 5000, mse: 0.002238238292304945\n"
          ]
        }
      ],
      "source": [
        "#memainkan jumlah epoch 1000 2000 3000 4000 5000\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.layers import Dense\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load the data\n",
        "data = df\n",
        "\n",
        "# Preprocess the data\n",
        "X = data.iloc[:, :-1].values\n",
        "y = data.iloc[:, -1].values\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Create the deep learning model\n",
        "#model = Sequential()\n",
        "#model.add(Dense(units=6, input_dim=5, activation='relu'))\n",
        "#model.add(Dense(units=6, activation='relu'))\n",
        "#model.add(Dense(units=1, activation='linear'))\n",
        "\n",
        "# Create the deep learning model\n",
        "model = Sequential()\n",
        "model.add(Dense(units= best_input_node , input_dim=5, activation='relu')) #input layer\n",
        "for i in range (best_hidden_layer):\n",
        "    model.add(Dense(units=best_node, activation='relu'))   #hidden layer 1\n",
        "model.add(Dense(units=1, activation='relu'))   #output layer\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Define epochs to train\n",
        "epochs = [1000, 2000, 3000, 4000, 5000]\n",
        "\n",
        "# Train the model for each epoch and evaluate\n",
        "best_mse = float('inf')\n",
        "best_epoch = 0\n",
        "for epoch in epochs:\n",
        "    print(f'Training for {epoch} epochs')\n",
        "    history = model.fit(X_train_scaled, y_train, batch_size = 10, epochs=epoch, verbose = 0)\n",
        "    score = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
        "    print('Test loss:', score)\n",
        "    \n",
        "    # Make predictions\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    \n",
        "    # calculate the mean squared error\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    print(\"Mean Squared Error for {} epoch: {:.4f}\".format(epoch, mse))\n",
        "    \n",
        "    # Check if the current epoch gives a lower loss\n",
        "    if mse < best_mse:\n",
        "        best_mse = mse\n",
        "        best_epoch = epoch\n",
        "\n",
        "    # mengekstrak eppoct dan mse dari history\n",
        "    epoch_i = np.arange(1, len(history.history['loss']) + 1) \n",
        "    mse = history.history['loss'] #Create a pandas dataframe to store the epoch and MSE \n",
        "    \n",
        "    df_history = pd.DataFrame({'Epoch': epoch_i, 'MSE': mse})\n",
        "    \n",
        "    #saving\n",
        "    filename = 'training_history_{}epoch.csv'.format(epoch)\n",
        "    df_history.to_csv(filename, index = False)\n",
        "    \n",
        "print(f'Best epoch: {best_epoch}, mse: {best_mse}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K0U6a1toOkCv"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}